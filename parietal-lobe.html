<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parietal Lobe</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="page-content">
        <h1>RESEARCH</h1>
        <p>The PARIETAL LOBE integrates information and supports problem-solving.<br>
           Here you’ll find my research experience and academic projects.</p>

    <p class="note">*These are brief descriptions of the projects I’ve worked on. For details on my specific contributions, see my <a href="papers/Shreya_Singh_CV_Website.pdf">CV</a>.</p>

        <div class="research-section">
            <h2>RESEARCH EXPERIENCE</h2>
            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/nhrcimage.jpg" alt="EEG signals">
                </div>
                <div class="project-description">
                    <h3 id="nhrc"> Image Reconstruction From Electroencephalogram (EEG)</h3>
                    <p class="lab"> Naval Health Research Center, San Diego</p>
                    <p class="content"> This project investigates reconstructing visual stimuli from EEG signals using advanced machine learning techniques, with a focus on potential applications for Navy research. 
                        Our work aims to better understand how brain activity encodes visual information and how it can be interpreted. </p>
                </div>
            </div>

            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/cvlimage.jpg" alt="Pitcher Pouring Water (Agent-Patient Relation)">
                </div>
                <div class="project-description">
                    <h3 id="cvl"> Role Recognition in Brief Displays</h3>
                    <p class="lab"> Computational Vision and Learning Lab, UCLA</p>
                    <p class="content"> This study investigates how people recognize event roles (e.g., who is the agent or patient) in naturalistic images, with the goal of advancing our understanding of visual event perception. 
                        I assisted with experiment administration, participant data collection, and stimulus preparation, and wrote a <a href="papers/Shreya_Singh_RoleRecognitionPaper.pdf" target="_blank">capstone research paper</a> summarizing my work over the quarter. </p>
                </div>
            </div>

            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/csnimage.png" alt="Overhead Brain MRI Scan">
                </div>
                <div class="project-description">
                    <h3 id="csn"> Dorm Social Network Study</h3>
                    <p class="lab"> Computational Social Neuroscience Lab, UCLA</p>
                    <p class="content"> This project investigated how social closeness influences neural responses to gaze cues. 
                        The team mapped the social network of a college dorm and used fMRI to record participants’ brain activity while they viewed images of floormates looking in different directions. 
                        I contributed by assisting with participant recruitment and data collection. </p>
                </div>
            </div>

            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/desalabimage.png" alt="Brain Illustration">
                </div>
                <div class="project-description">
                    <h3>Reconstruction From EEG Across Modalities</h3>
                    <p class="lab"> De Sa Lab, UCSD</p>
                    <p class="content"> As a research intern, I reviewed and annotated literature on advanced EEG methodologies, focusing on neural networks, dimensionality reduction techniques, and visual reconstruction.
                        The lab’s work centered on reconstructing images or sounds from EEG data, which gave me exposure to computational models such as PCA, autoencoders, and diffusion models, and their applications in brain signal decoding. </p>
                </div>
            </div>
        </div>

        <div class="academic-section">
            <h2>ACADEMIC PROJECTS</h2>
            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/fewshotimage.jpg" alt="Child Playing with Animal Toys">
                </div>
                <div class="project-description">
                    <h3>Few-Shot Learning: A Literature Review and Research Proposal</h3>
                    <p class="lab">Course: Perception, Learning, and Learning Technologies (PSYCH 124J)</p>
                    <p class="content"> I wrote a research paper that synthesizes existing literature on few-shot learning, drawing parallels between human and machine learning. 
                    The paper proposes a new study to test whether inductive biases are innate or can be shaped through training, with implications for both developmental psychology and the design of more human-like AI systems. 
                    Read the paper <a href="papers/Shreya_Singh_FewShotLearningPaper.pdf" target="_blank">here</a>. </p>
                </div>
            </div>
            <div class="research-project">
                <div class="project-image">
                    <img src="images/research/penguinprojectimage.jpg" alt="Adelie Penguin">
                </div>
                <div class="project-description">
                    <h3>Penguin Species Classification Project</h3>
                    <p class="lab"> Course: Python with Applications (PIC 16A) </p>
                    <p class="content">This project involved a comparative analysis of two machine learning models, Logistic Regression and Random Forest Classification, for classifying penguin species. 
                        We programmed the models, optimized feature selection, and performed hyperparameter tuning, culminating in a Random Forest classifier that achieved a final accuracy of 97.6%. 
                        See our code <a href="https://github.com/shreya025/Penguin-Classification- " target="_blank">here</a>.</p>
                </div>
            </div>
        </div>

        <a href="index.html" class="brain-button">
            <img src="logos/brain.svg" alt="Back to brain page">
        </a>
    </div>
</body>
</html>